# ChatGpt â€” Realâ€‘time AI Chat Backend âœ¨ğŸ¤–

Summary ğŸ§­
- Purpose: Node.js backend for an AI chat app with user auth, chat threads, realâ€‘time replies via Socket.IO, and longâ€‘term memory using Pinecone. âœï¸
- Status: MVP working for local dev and demo. ğŸš¦
- Owner(s): Yashaswirai. ğŸ‘¤
- Live URL (demo): https://chatgpt-sc2z.onrender.com (API base at `/api`, Socket at root). ğŸ”—
- Repo: Monorepo with `Backend/` and `Frontend/`. ğŸ—‚ï¸

## Table of Contents ğŸ“š
- Overview ğŸš€
- Features âœ¨
- Architecture ğŸ—ï¸
- Project Layout ğŸ—‚ï¸
- Setup âš™ï¸
- Configuration ğŸ”§
- Usage â–¶ï¸
- API ğŸ”Œ
- Sockets ğŸ”Œâš¡
- Data Model ğŸ—ƒï¸
- Prompting & AI Integration ğŸ¤–ğŸ§ 
- Quality (Testing, Linting) âœ…
- Build & Deploy ğŸš¢
- Security & Compliance ğŸ”
- Observability ğŸ‘€
- Performance & Cost âš¡
- Roadmap ğŸ—ºï¸
- Changelog ğŸ“
- License ğŸ“„
- FAQ & Troubleshooting â“ğŸ’¡

## Overview ğŸš€
- Problem: Provide a backend that can authenticate users, organize chats, generate AI responses, and retain context across sessions. ğŸ¯
- Solution: Express + MongoDB API, Socket.IO for realâ€‘time chat, Google GenAI for text generation and embeddings, Pinecone for vector memory (RAGâ€‘style retrieval). ğŸ§©
- Nonâ€‘goals: Admin UI, provider abstraction, multiâ€‘tenant RBAC. ğŸš«

## Features âœ¨
Current
- ğŸ” JWT auth with cookies (register/login/status/logout).
- ğŸ§µ Chat thread CRUD (create, read, update title, delete).
- ğŸ’¾ Message persistence and retrieval per chat.
- âš¡ Realâ€‘time AI replies over WebSockets.
- ğŸ§  Longâ€‘term memory via Pinecone using Google GenAI embeddings.

Planned
- ğŸ—³ï¸ Streaming token responses.
- ğŸ›¡ï¸ Rate limiting and input validation.
- ğŸ§ª Basic tests and linting.

## Architecture ğŸ—ï¸
- Backend/API: Express 5 on Node.js; Socket.IO for realtime. ğŸ§±
- AI Provider: Google GenAI
  - Text model: `gemini-2.5-flash`
  - Embedding model: `gemini-embedding-001`
- Data: MongoDB (Mongoose) for users/chats/messages; Pinecone index `chatgpt` for vectors (dim 768). ğŸ—„ï¸
- Auth: JWT via `token` cookie for HTTP and Socket.IO handshake. ğŸ”
- Observability: Console logging. ğŸ“Š

Data flow ğŸ”„
1) Client emits `ai-message` with `{ chatId, content }`.
2) Server saves the user message, creates an embedding, and upserts to Pinecone.
3) Server fetches topâ€‘K related memories and recent chat history.
4) Builds prompt from LTM + STM and calls Google GenAI.
5) Emits `ai-response` and persists the model reply and its embedding.

## Project Layout ğŸ—‚ï¸
```
Backend/
  package.json
  Readme.md
  server.js
  public/
    index.html
    assets/*
  src/
    app.js
    controllers/
      auth.controller.js
      chat.controller.js
    db/
      db.js
    middlewares/
      auth.middleware.js
    models/
      chat.model.js
      message.model.js
      user.model.js
    routes/
      auth.routes.js
      chat.routes.js
    services/
      Ai.service.js
      Vector.service.js
    socket/
      socket.server.js
```

## Setup âš™ï¸
Prerequisites ğŸ§°
- Node.js LTS (18+) and npm
- MongoDB database (Atlas/local)
- Pinecone account with index `chatgpt` (dimension 768)
- Google Generative AI API key

Install dependencies ğŸ“¦ (Windows PowerShell)
```powershell
cd Backend
npm install
```

Environment ğŸŒ±
Create `Backend/.env`:
```
PORT=3000
MONGODB_URI=mongodb://localhost:27017/MERN-GPT
JWT_SECRET=replace_with_a_long_random_string
GOOGLE_API_KEY=your_google_genai_api_key
PINECONE_API_KEY=your_pinecone_api_key
```

Start dev â–¶ï¸
```powershell
cd Backend
npm run dev
```
- Server: http://localhost:3000
- CORS (HTTP & Socket.IO) default origin: `http://localhost:5173` with credentials

## Configuration ğŸ”§
Environment variables ğŸ”‘
- `PORT`: HTTP port (default 3000)
- `MONGODB_URI`: MongoDB connection string
- `JWT_SECRET`: Secret to sign/verify JWTs
- `GOOGLE_API_KEY`: Google Generative AI API key (used by `@google/genai`)
- `PINECONE_API_KEY`: Pinecone API key (index name `chatgpt`)

Notes
- Ensure Pinecone index `chatgpt` exists with dimension 768.
- Cookie name is `token`; frontend must set `withCredentials: true` on axios and Socket.IO.
- Update CORS origins in `src/app.js` and `src/socket/socket.server.js` for production.

## Usage â–¶ï¸
Auth flow (cookies)
1) `POST /api/auth/register` â†’ sets `token` cookie
2) `POST /api/auth/login` â†’ sets `token` cookie
3) `GET /api/auth/status` â†’ verifies session
4) `GET /api/auth/logout` â†’ clears `token`

Chats
- `POST /api/chat` (auth) with `{ "title": "My Chat" }` â†’ returns new chat
- Use `GET /api/chat/:id/messages` to fetch conversation
- Use Socket.IO to send messages and receive AI responses

## API ğŸ”Œ
Conventions
- JSON; cookieâ€‘based JWT; standard status codes on failures.

Auth
- `POST /api/auth/register`
  - Body: `{ username, email, password }`
  - 201; sets cookie `token`; returns `{ message, newUser }`
- `POST /api/auth/login`
  - Body: `{ identifier, password }` (identifier = username or email)
  - 200; sets cookie `token`; returns `{ message, user }`
- `GET /api/auth/status` â†’ `{ isAuthenticated, user? }`
- `GET /api/auth/logout` â†’ `{ message }`

Chats
- `GET /api/chat` (auth) â†’ `{ chats }` (sorted by `updatedAt` desc)
- `POST /api/chat` (auth) â†’ `{ message, chat }`
- `GET /api/chat/:id` (auth) â†’ `{ chat }`
- `PUT /api/chat/:id` (auth) body `{ title }` â†’ `{ message, chat }`
- `DELETE /api/chat/:id` (auth) â†’ `{ message }` and deletes associated messages + vectors
- `GET /api/chat/:id/messages` (auth) â†’ `{ messages }` (ascending by `createdAt`)
- `GET /api/chat/prompts` (auth) â†’ `{ prompts }` (onboarding suggestions)

Errors ğŸ§¯
- 400 duplicate user, 401 unauthorized, 404 not found, 500 server errors

## Sockets ğŸ”Œâš¡
Namespace: default
- Auth: via `token` cookie parsed during Socket.IO handshake.

Events
- Client â†’ Server: `ai-message`
  - Payload: `{ chatId: string, content: string }`
- Server â†’ Client: `ai-response`
  - Payload: `{ chatId: string, response: string }`

Flow
1) Persist user message (MongoDB) and embed â†’ upsert to Pinecone.
2) Retrieve topâ€‘K memory (LTM) and last 7 messages (STM).
3) Compose prompt and call Google GenAI.
4) Emit `ai-response`, persist model reply, embed + store in Pinecone.

## Data Model ğŸ—ƒï¸
User
- `username` (unique, required)
- `email` (unique, required)
- `password` (hash)

Chat
- `userId` (ref User, required)
- `title` (required)

Message
- `chatId` (ref Chat, required)
- `sender` (ref User, required)
- `content` (string, required)
- `role` ("user" | "model" | "system")

## Prompting & AI Integration ğŸ¤–ğŸ§ 
- Models: `gemini-2.5-flash` (text), `gemini-embedding-001` (embeddings, 768 dims)
- LTM injected as a systemâ€‘style message with concatenated Pinecone match contents
- STM built from the last 7 chat messages
- Request format uses Google GenAI `contents` array with `{ role, parts: [{ text }] }`

## Quality (Testing, Linting) âœ…
- No tests or linters configured yet.
- Suggested: add ESLint + unit tests for controllers/middleware.

## Build & Deploy ğŸš¢
- Node service (no build step for backend). Run with `node server.js` in production.
- Provide required env vars and ensure MongoDB/Pinecone/Google access.
- Set proper CORS origins and secure cookie options in production.

## Security & Compliance ğŸ”
- JWT stored in cookie `token`.
- Recommendations: set `HttpOnly`, `Secure`, `SameSite` on cookies; rotate `JWT_SECRET`; validate inputs; rate limit auth and chat endpoints.

## Observability ğŸ‘€
- Console logs only. Consider adding request logging (morgan) and error tracking (Sentry, etc.).

## Performance & Cost âš¡
- Embedding 768 dims; topK default 2 for memory queries.
- Consider caching frequent prompts and batching embeddings.

## Roadmap ğŸ—ºï¸
- [ ] Streaming responses over Socket.IO
- [ ] Rate limiting and input validation
- [ ] Add tests and linting

## Changelog ğŸ“
- 2025â€‘08â€‘25: Updated README to reflect actual endpoints, env location, and live URL.

## License ğŸ“„
- TBD

## FAQ & Troubleshooting â“ğŸ’¡
- MongoDB connection error: verify `MONGODB_URI` and network access.
- Unauthorized/401: ensure `token` cookie is present; set `JWT_SECRET` and reâ€‘login.
- Pinecone errors: ensure `PINECONE_API_KEY` and index `chatgpt` (dim 768) exist.
- No AI response: check `GOOGLE_API_KEY` and model availability.
- CORS issues in prod: update allowed origins in `src/app.js` and `src/socket/socket.server.js` to your frontend domain.
